{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57853cff",
   "metadata": {},
   "source": [
    "# 1. What is the underlying concept of Support Vector Machines?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c191cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans : SVM or Support Vector Machine is a linear model for classification and regression problems. It can solve linear and \n",
    "#       non-linear problems and work well for many practical problems. The idea of SVM is simple: The algorithm creates a line\n",
    "#       or a hyperplane which separates the data into classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ee336b",
   "metadata": {},
   "source": [
    "# 2. What is the concept of a support vector?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64eeaac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans : Support vectors are data points that are closer to the hyperplane and influence the position and orientation of the \n",
    "#       hyperplane. Using these support vectors, we maximize the margin of the classifier. Deleting the support vectors will \n",
    "#       change the position of the hyperplane. These are the points that help us build our SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b000e69d",
   "metadata": {},
   "source": [
    "# 3. When using SVMs, why is it necessary to scale the inputs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73ae20f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans : Feature scaling is crucial for some machine learning algorithms, which consider distances between observations because\n",
    "#       the distance between two observations differs for non-scaled and scaled cases. Hence, the distance between data points\n",
    "#       affects the decision boundary SVM chooses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e056fa",
   "metadata": {},
   "source": [
    "# 4. When an SVM classifier classifies a case, can it output a confidence score? What about a percentage chance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dee8a8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans : An SVM classifier can output the distance between the test instance and the decision boundary, and you can use this as \n",
    "#       a confidence score. However, this score cannot be directly converted into an estimation of the class probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a23a68",
   "metadata": {},
   "source": [
    "# 5. Should you train a model on a training set with millions of instances and hundreds of features using the primal or dual form of the SVM problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "092d7b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans :  If there are millions of instances, you should definitely use the primal form, because the dual form will be much too \n",
    "#        slow. Say you trained an SVM classifier with an RBF kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43c0aa0",
   "metadata": {},
   "source": [
    "# 6. Let&#39;s say you&#39;ve used an RBF kernel to train an SVM classifier, but it appears to underfit the training collection. Is it better to raise or lower (gamma)? What about the letter C?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6c36b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans : Gaussian Kernel Radial Basis Function (RBF) : Same as above kernel function, adding radial basis method to improve \n",
    "#       the transformation. Also The gamma parameter in SVM tuning signifies the influence of points either near or far \n",
    "#       away from the hyperplane.\n",
    "#       The C parameter trades off correct classification of training examples against maximization of the decision function's\n",
    "#       margin.For larger values of C , a smaller margin will be accepted if the decision function is better at classifying all\n",
    "#       training points correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bd3477",
   "metadata": {},
   "source": [
    "# 7. To solve the soft margin linear SVM classifier problem with an off-the-shelf QP solver, how should the QP parameters (H, f, A, and b) be set? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6f60c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans : "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dc5de6",
   "metadata": {},
   "source": [
    "# 8. On a linearly separable dataset, train a LinearSVC. Then, using the same dataset, train an SVC and an SGDClassifier. See if you can get them to make a model that is similar to yours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12313624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans : "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
